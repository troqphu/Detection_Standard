# ğŸ” Detection Standard - AI Fake Product Detection System

<div align="center">

![AI Detection](https://img.shields.io/badge/AI-Detection-blue)
![Vision Transformer](https://img.shields.io/badge/Model-Vision%20Transformer-green)
![Accuracy](https://img.shields.io/badge/Accuracy-90%2B%25-brightgreen)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-orange)

**Há»‡ thá»‘ng AI phÃ¢n tÃ­ch vÃ  phÃ¡t hiá»‡n sáº£n pháº©m giáº£ máº¡o vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao**

[ğŸŒ Live Demo](http://127.0.0.1:8000) â€¢ [ğŸ“š API Docs](http://127.0.0.1:8000/docs) â€¢ [ğŸš€ Quick Start](#-quick-start)

</div>

## âœ¨ TÃ­nh nÄƒng ná»•i báº­t

- ğŸ¯ **Äá»™ chÃ­nh xÃ¡c cao**: 90%+ vá»›i Vision Transformer
- ğŸ”¬ **Explainable AI**: PhÃ¢n tÃ­ch chi tiáº¿t lÃ½ do phÃ¡n Ä‘oÃ¡n
- ğŸ¨ **Attention Heatmap**: Visualize vÃ¹ng AI táº­p trung phÃ¢n tÃ­ch
- ğŸŒ **Web Interface**: Giao diá»‡n hiá»‡n Ä‘áº¡i, thÃ¢n thiá»‡n ngÆ°á»i dÃ¹ng
- âš¡ **Real-time API**: FastAPI vá»›i tá»‘c Ä‘á»™ xá»­ lÃ½ nhanh
- ğŸ“Š **PhÃ¢n tÃ­ch chuyÃªn sÃ¢u**: ÄÃ¡nh giÃ¡ texture, cáº¥u trÃºc, cháº¥t liá»‡u
- ğŸ”„ **Multi-scale Analysis**: PhÃ¢n tÃ­ch Ä‘a má»©c Ä‘á»™ chi tiáº¿t

## ğŸš€ Quick Start

### 1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Clone repository
git clone https://github.com/troqphu/Detection_Standard.git
cd Detection_Standard

# Táº¡o virtual environment (khuyáº¿n nghá»‹)
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# CÃ i Ä‘áº·t dependencies
pip install -r config/requirements.txt
```

### 2. Cháº¡y á»©ng dá»¥ng

```bash
# Cháº¡y API server
python simple_api.py
```

Truy cáº­p:
- ğŸŒ **Web Interface**: http://127.0.0.1:8000
- ğŸ“‹ **API Documentation**: http://127.0.0.1:8000/docs
- âœ… **Health Check**: http://127.0.0.1:8000/status

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
Detection_Standard/
â”œâ”€â”€ ğŸ”§ simple_api.py          # Entry point - khá»Ÿi cháº¡y server
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€  api.py             # FastAPI server chÃ­nh
â”‚   â”œâ”€â”€  explainer.py       # AI explanation & analysis
â”‚   â”œâ”€â”€  train.py           # Training pipeline
â”‚   â”œâ”€â”€ ğŸ“ models/
â”‚   â”‚   â”œâ”€â”€ model.py          # Vision Transformer architecture
â”‚   â”‚   â””â”€â”€ se_module.py      # Squeeze-and-Excitation module
â”‚   â”œâ”€â”€ ğŸ“ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py        # Data loading utilities
â”‚   â”‚   â”œâ”€â”€ ğŸ“ train/         # Training data
â”‚   â”‚   â”œâ”€â”€ ğŸ“ validation/    # Validation data
â”‚   â”‚   â””â”€â”€ ğŸ“ test/          # Test data
â”‚   â””â”€â”€ ğŸ“ utils/
â”‚       â”œâ”€â”€ utils.py          # Utility functions
â”‚       â””â”€â”€ heatmap_utils.py  # Heatmap generation
â”œâ”€â”€  web/
â”‚   â”œâ”€â”€ index.html           # Modern web interface
â”‚   â””â”€â”€ app.js               # Frontend JavaScript
â”œâ”€â”€  config/
â”‚   â”œâ”€â”€ config.yaml          # Model & training configuration
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€  results/              # Trained models & outputs
â”œâ”€â”€  uploads/              # Generated heatmaps
â””â”€â”€  logs/                 # System logs
```

## ğŸ¯ CÃ¡ch sá»­ dá»¥ng

### ğŸŒ Web Interface

1. Má»Ÿ http://127.0.0.1:8000
2. Upload áº£nh sáº£n pháº©m cáº§n phÃ¢n tÃ­ch
3. Xem káº¿t quáº£ vá»›i:
   - âœ…/âŒ PhÃ¡n Ä‘oÃ¡n CHÃNH HÃƒNG/GIáº¢
   - ğŸ“Š Äá»™ tin cáº­y (%)
   - ğŸ”¬ PhÃ¢n tÃ­ch chi tiáº¿t
   - ğŸ¨ Heatmap attention

### ğŸ”Œ API Usage

#### Upload file trá»±c tiáº¿p:

```python
import requests

# Upload áº£nh
files = {'file': open('product_image.jpg', 'rb')}
response = requests.post('http://127.0.0.1:8000/analyze', files=files)
result = response.json()

print(f"Káº¿t quáº£: {result['prediction']}")
print(f"Äá»™ tin cáº­y: {result['confidence']:.2f}")
print(f"PhÃ¢n tÃ­ch: {result['analysis']}")
print(f"Heatmap: {result['heatmap']}")
```

#### Predict qua JSON:

```python
import requests

response = requests.post('http://127.0.0.1:8000/predict', 
                        files={'file': open('image.jpg', 'rb')})
result = response.json()

print(f"Prediction: {result['prediction']}")
print(f"Confidence: {result['confidence']}")
```

## ğŸ§  AI Model Architecture

### Vision Transformer vá»›i Enhanced Features

- **Backbone**: Vision Transformer (ViT) vá»›i patch size 16x16
- **Multi-Head Attention**: 8 attention heads cho phÃ¢n tÃ­ch Ä‘a chiá»u
- **Squeeze-and-Excitation**: TÄƒng cÆ°á»ng channel attention
- **Multi-scale Fusion**: Káº¿t há»£p thÃ´ng tin tá»« nhiá»u scale
- **Explainable Features**: Attention maps cho visualization

### CÃ¡c chá»‰ sá»‘ phÃ¢n tÃ­ch

ğŸ”¬ **Metrics Ä‘Æ°á»£c AI Ä‘Ã¡nh giÃ¡:**
- **Sharpness**: Äá»™ sáº¯c nÃ©t hÃ¬nh áº£nh
- **Symmetry**: TÃ­nh Ä‘á»‘i xá»©ng cáº¥u trÃºc
- **Texture**: Äá»™ phá»©c táº¡p bá» máº·t
- **Edge Precision**: Äá»™ chÃ­nh xÃ¡c Ä‘Æ°á»ng viá»n
- **Material Quality**: Cháº¥t lÆ°á»£ng váº­t liá»‡u
- **Color Consistency**: TÃ­nh nháº¥t quÃ¡n mÃ u sáº¯c

## ğŸ“ Training Model

### Chuáº©n bá»‹ dataset

```
src/data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ fake/     # áº¢nh sáº£n pháº©m giáº£
â”‚   â””â”€â”€ real/     # áº¢nh sáº£n pháº©m tháº­t
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ fake/     # Validation - giáº£
â”‚   â””â”€â”€ real/     # Validation - tháº­t
â””â”€â”€ test/
    â”œâ”€â”€ fake/     # Test - giáº£  
    â””â”€â”€ real/     # Test - tháº­t
```

### Cháº¡y training

```bash
cd src
python train.py
```

**Training features:**
- âš¡ Mixed precision training
- ğŸ”„ Data augmentation
- ğŸ“Š Real-time monitoring
- ğŸ’¾ Auto checkpoint saving
- ğŸ“ˆ TensorBoard logging

## ğŸ”§ Configuration

Chá»‰nh sá»­a `config/config.yaml`:

```yaml
model:
  image_size: 224
  patch_size: 16
  num_classes: 2
  embed_dim: 512
  depth: 12
  heads: 8
  mlp_ratio: 4.0
  dropout: 0.1

training:
  batch_size: 32
  learning_rate: 0.0001
  epochs: 100
  weight_decay: 0.01
  
augmentation:
  rotation: 15
  brightness: 0.2
  contrast: 0.2
  saturation: 0.2
```

## ğŸ“Š Performance

| Metric | Score |
|--------|-------|
| **Accuracy** | 92.3% |
| **Precision** | 91.8% |
| **Recall** | 93.1% |
| **F1-Score** | 92.4% |
| **AUC-ROC** | 0.967 |

## ğŸ› ï¸ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Web interface |
| `/analyze` | POST | PhÃ¢n tÃ­ch áº£nh (upload file) |
| `/predict` | POST | Dá»± Ä‘oÃ¡n Ä‘Æ¡n giáº£n |
| `/status` | GET | Tráº¡ng thÃ¡i há»‡ thá»‘ng |
| `/docs` | GET | API documentation |

## ğŸ” Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

1. **ModuleNotFoundError**: 
   ```bash
   pip install -r config/requirements.txt
   ```

2. **CUDA out of memory**:
   - Giáº£m batch_size trong config.yaml
   - Hoáº·c cháº¡y trÃªn CPU

3. **Port already in use**:
   - API tá»± Ä‘á»™ng tÃ¬m port trá»‘ng (8000-8009)

### System Requirements

- **Python**: 3.8+
- **RAM**: 8GB+ (khuyáº¿n nghá»‹ 16GB)
- **GPU**: Optional (CUDA-compatible)
- **Storage**: 5GB+ free space

## ğŸ¤ Contributing

1. Fork repository
2. Táº¡o feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Táº¡o Pull Request

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.

## ğŸ‘¥ Authors

- **[@troqphu](https://github.com/troqphu)** - *Initial work*

## ğŸ™ Acknowledgments

- Vision Transformer paper authors
- FastAPI framework
- PyTorch community
- All contributors

---

<div align="center">

**â­ Star this repo if you find it helpful!**

[![GitHub stars](https://img.shields.io/github/stars/troqphu/Detection_Standard?style=social)](https://github.com/troqphu/Detection_Standard/stargazers)

</div> 